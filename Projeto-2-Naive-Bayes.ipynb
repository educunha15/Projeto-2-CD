{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importando os dois dataframes\n",
    "\n",
    "excel = pd.ExcelFile('tweets_airpods_201809062235.xlsx')\n",
    "data_treinamento = pd.read_excel(excel, 'Treinamento')\n",
    "data_teste = pd.read_excel(excel, 'Teste')\n",
    "\n",
    "# Limpando as colunas Treinamento e Teste dos dataframes\n",
    "\n",
    "treinamento = data_treinamento['Treinamento'].str.replace('@', '')\n",
    "treinamento = treinamento.str.replace('rt', '')\n",
    "treinamento = treinamento.str.replace(',', '')\n",
    "treinamento = treinamento.str.replace('.', '')\n",
    "treinamento = treinamento.str.replace(':', '')\n",
    "treinamento = treinamento.str.replace(';', '')\n",
    "treinamento = treinamento.str.replace('\\n', '')\n",
    "treinamento = treinamento.str.replace('\"', '')\n",
    "\n",
    "teste = data_teste['Teste'].str.replace('@', '')\n",
    "teste = teste.str.replace('rt', '')\n",
    "teste = teste.str.replace(',', '')\n",
    "teste = teste.str.replace('.', '')\n",
    "teste = teste.str.replace(':', '')\n",
    "teste = teste.str.replace(';', '')\n",
    "teste = teste.str.replace('\\n', '')\n",
    "teste = teste.str.replace('\"', '')\n",
    "\n",
    "# Inserindo as colunas limpas em seus respectivos dataframes\n",
    "\n",
    "data_treinamento['Treinamento'] = treinamento\n",
    "data_teste['Teste'] = teste\n",
    "\n",
    "# Selecionando os relevantes e irrelevantes da base de treinamento\n",
    "\n",
    "Relevantes = data_treinamento[data_treinamento['PRODUTO : APPLE AIRPODS'] == 'Relevante']\n",
    "Irrelevantes = data_treinamento[data_treinamento['PRODUTO : APPLE AIRPODS'] == 'Irrelevante']\n",
    "\n",
    "# Definindo P(Relevante) e P(Irrelevante)\n",
    "\n",
    "PRelevante = len(Relevantes)/len(data_treinamento)\n",
    "PIrrelevante = len(Irrelevantes)/len(data_treinamento)\n",
    "\n",
    "# Comparando P(Relevante|tweet) com P(Irrelevante|tweet)\n",
    "# P(Relevante|tweet) = P(tweet|Relevante) x P(Relevante)\n",
    "# P(Irrelevante|tweet) = P(tweet|Irrelevante) x P(Irrelevante)\n",
    "\n",
    "# Criando as listas com tweets, sendo cada um uma lista com as palavras separadas\n",
    "\n",
    "lista_tweets = []\n",
    "lista_tweets_relevantes = []\n",
    "lista_tweets_irrelevantes = []\n",
    "\n",
    "for tweet in Relevantes['Treinamento']:\n",
    "    lista_tweets_relevantes.append(tweet.split())\n",
    "    \n",
    "for tweet in Irrelevantes['Treinamento']:\n",
    "    lista_tweets_irrelevantes.append(tweet.split())\n",
    "\n",
    "for tweet in treinamento:\n",
    "    lista_tweets.append(tweet.split())\n",
    "    \n",
    "# Verificando palavras possiveis para Laplace Smoothing\n",
    "\n",
    "palavras_possiveis = []\n",
    "\n",
    "for tweet in lista_tweets:\n",
    "    for palavra in tweet:\n",
    "        if palavra.lower() not in palavras_possiveis:\n",
    "            palavras_possiveis.append(palavra.lower())\n",
    "            \n",
    "# Calcula P(palavra|Relevante) com Laplace Smoothing    \n",
    "    \n",
    "def ProbRelevante(palavra):\n",
    "    ocorrencia = 1\n",
    "    total_de_palavras = 0\n",
    "    \n",
    "    for tweet in lista_tweets_relevantes:\n",
    "        total_de_palavras += len(tweet)\n",
    "        \n",
    "        for i in tweet:\n",
    "            if i.lower() == palavra.lower():\n",
    "                ocorrencia += 1\n",
    "                \n",
    "    return ocorrencia/(total_de_palavras + len(palavras_possiveis))\n",
    "\n",
    "# Calcula P(palavra|Irrelevante) com Laplace Smoothing\n",
    "\n",
    "def ProbIrrelevante(palavra):\n",
    "    ocorrencia = 1\n",
    "    total_de_palavras = 0\n",
    "    \n",
    "    for tweet in lista_tweets_irrelevantes:\n",
    "        total_de_palavras += len(tweet)\n",
    "        \n",
    "        for i in tweet:\n",
    "            if i.lower() == palavra.lower():\n",
    "                ocorrencia += 1\n",
    "    \n",
    "    return ocorrencia/(total_de_palavras + len(palavras_possiveis))\n",
    "\n",
    "# Classificando os tweets da base de treinamento\n",
    "\n",
    "def classifica(lista_de_tweets):\n",
    "    classificacao = []\n",
    "\n",
    "    for tweet in lista_de_tweets: \n",
    "        PPRelevantes = []\n",
    "        PPIrrelevantes = []\n",
    "\n",
    "        for palavra in tweet:\n",
    "            PPRelevantes.append(ProbRelevante(palavra))\n",
    "            PPIrrelevantes.append(ProbIrrelevante(palavra))\n",
    "\n",
    "        PTweetRelevante = 1\n",
    "        PTweetIrrelevante = 1\n",
    "\n",
    "        for i in PPRelevantes:\n",
    "            PTweetRelevante *= i\n",
    "\n",
    "        for i in PPIrrelevantes:\n",
    "            PTweetIrrelevante *= i\n",
    "\n",
    "        PRelevanteTweet = PTweetRelevante * PRelevante\n",
    "        PIrrelevanteTweet = PTweetIrrelevante * PIrrelevante\n",
    "\n",
    "        if PRelevanteTweet > PIrrelevanteTweet:\n",
    "            classificacao.append('Relevante')\n",
    "        else:\n",
    "            classificacao.append('Irrelevante')\n",
    "    return classificacao\n",
    "\n",
    "lista_tweets_teste = []\n",
    "for tweet in teste:\n",
    "    lista_tweets_teste.append(tweet)\n",
    "\n",
    "classificacao = classifica(lista_tweets_teste)\n",
    "\n",
    "gabarito = data_teste.rename(index=str, columns={'Unnamed: 1':'Relevancia'}).Relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.035\n",
      "0.43\n",
      "0.455\n",
      "0.08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "falpos = 0\n",
    "falneg = 0\n",
    "verpos = 0\n",
    "verneg = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(gabarito)):\n",
    "    if gabarito[i] == classificacao[i] and gabarito[i] == 'Relevante':\n",
    "        verpos += 1\n",
    "    elif gabarito[i] == classificacao[i] and gabarito[i] == 'Irrelevante':\n",
    "        verneg += 1\n",
    "    elif gabarito[i] != classificacao[i] and gabarito[i] == 'Relevante':\n",
    "        falneg += 1\n",
    "    else:\n",
    "        falpos += 1\n",
    "\n",
    "falpos /= len(classificacao)\n",
    "falneg /= len(classificacao)\n",
    "verpos /= len(classificacao)\n",
    "verneg /= len(classificacao)\n",
    "\n",
    "print(falpos+falneg+verpos+verneg)\n",
    "\n",
    "print(falneg)\n",
    "print(falpos)\n",
    "print(verneg)\n",
    "print(verpos)\n",
    "\n",
    "len(classificacao)\n",
    "        \n",
    "\n",
    "#data_teste2.Relevância\n",
    "#classificacao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
